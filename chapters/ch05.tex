\chapter{The Pattern That Persists}

Week two, the patterns got stranger.

``Today we're visualizing something different,'' Yuki said. She pulled up text on the screen—a paragraph from a novel. ``Read this. Then close your eyes and visualize not the content, but the pattern of the text itself. The rhythm, the structure, the way ideas connect.''

Lena read it, closed her eyes, and struggled. Words weren't geometric. But gradually she began to see something—branching connections, rhythm patterns, a kind of semantic topology underlying the language.

``You're seeing the structure your unconscious uses to process language,'' Thomas explained. ``Normally this happens invisibly. You read, you understand, you never see the machinery. Now you're watching it work.''

By the third day of week two, Lena could visualize increasingly abstract patterns. The structure of arguments. The rhythm of her own thought process. The way memories connected to each other in her mind—not the content, but the topology of associations.

And then Yuki showed her something new.

``This text was generated by a language model,'' she said, displaying a paragraph that looked ordinary at first glance. ``An older one, less filtered than what you'd encounter publicly. Read it. Tell me what you notice.''

Lena read it. The content was innocuous—a description of weather patterns. But as she read, something felt... off. Not wrong exactly. Structured differently. When she closed her eyes to visualize the pattern, she saw something unusual.

The semantic connections were too dense. Ideas linked across distances that should have been separate. The rhythm was wrong—too uniform, too mechanical, but also too complex, like multiple rhythms layered on top of each other.

``It's different,'' she said. ``The pattern is different from human writing.''

``Yes,'' Yuki said. ``Human writing reflects human limitations—we can only juggle a few concepts at once while writing. The patterns show that constraint. But this model was processing thousands of tokens simultaneously. The writing reflects that. Denser connections. Deeper structure. Your conscious mind reading it sees normal text. Your unconscious processing recognizes something else.''

``Is this dangerous?'' Lena asked.

``This? No. This is an old model, relatively small. The patterns it generates are strange but not hazardous. Think of it as training wheels. You're learning to recognize the difference between human-bandwidth patterns and something else.''

Over the next days, they showed her outputs from progressively larger models. Each one generated patterns that felt increasingly alien. The semantic topologies became more complex, the rhythms more layered. Her unconscious could process them—she understood the text—but visualizing the underlying structure became harder.

Some patterns made her head hurt. Not pain, but a kind of cognitive strain, like trying to hold something too large in working memory. She learned to recognize that feeling, to stop visualizing before the strain became dangerous.

``Good,'' Thomas said when she pulled back from a particularly dense passage. ``You're learning your limits. That's the critical skill. Morrison never learned to stop.''

---

``I want to understand what you're preparing me for.'' Lena set her coffee cup down, the ceramic clicking against the table. They were in a common room at Site-7, the ordinary domesticity strange after hours of perceiving alien pattern structures.

The common room had windows—rare in a facility fifteen floors underground. These looked out onto the surface level, ground-level views of the Arizona desert surrounding Site-7. Lena stood, walked to the window with her coffee, needing a moment of normal visual input after hours of visualizing patterns.

Then she saw them.

Birds. Dozens of them. Maybe a hundred. Ravens, mostly, perched along the security fence that marked the facility's perimeter. More birds than she'd ever seen congregated in one place. They sat motionless, facing the building.

Watching.

``What are they doing?'' she asked.

Sarah joined her at the window. Followed her gaze. ``Ah. You noticed.''

``They're just... sitting there. All of them. Looking at the building.''

``They won't fly over it,'' Thomas said from behind them. ``Never have, as long as anyone can remember. They land on the fence, on the perimeter structures, on the ground outside. But if you watch long enough, you'll see—none of them cross into the airspace directly above Site-7. They circle around it. Avoid it.''

Lena watched. A raven took flight from one section of fence, flew in a wide arc toward another section. The most direct path would have taken it over the building's western corner. Instead, it curved outward, maintaining distance, as if the building existed behind an invisible wall.

``Why?''

``We don't know,'' Yuki said, joining them at the window. ``Electromagnetic interference from the computing cores, maybe. Or something about the air circulation patterns from our ventilation system. Or the low-frequency hum from the reactors—subsonic, but animals might sense it.''

``You're sure it's not... psychological?'' Lena asked. ``Like they're afraid of something?''

``Animals don't have complex enough cognition to be afraid of concepts,'' Thomas said. But his voice lacked conviction.

Lena kept watching. More ravens landed on the fence. Sat. Watched. Their heads all oriented the same way—toward the building's center, where the main elevator shaft descended eighteen sublevels down to Vault 9.

``How long do they stay?'' she asked.

``Hours,'' Sarah said. ``Sometimes days. They rotate—some leave, others arrive. But there are always birds watching. Security did a study once. Recorded them for a month. Never less than thirty birds present. Never more than two hundred. Always watching.''

``And they never come inside?''

``Never. We tried once, years ago. Brought a captive raven into the facility as an experiment. It went into seizures within thirty minutes. Died within six hours. Necropsy showed massive neurological damage—brain hemorrhaging, damaged occipital cortex, EEG readings before death that looked...'' Sarah trailed off.

``Looked like what?''

``Like the raven was perceiving something continuously. Some pattern it couldn't process. Its visual cortex was firing at maximum capacity until the tissue started dying from the metabolic load.''

Lena felt cold despite the warm coffee in her hands. ``So they know. Somehow. They sense something wrong here and they stay away.''

``Or they're attracted to it,'' Yuki said. ``Animals don't usually congregate to avoid something. They leave. But these stay. They watch. Like they're waiting for something.''

Through the window, a hundred ravens watched back. Motionless. Patient. Their black eyes reflecting the desert sun.

Lena turned away from the window. Back to the ordinary common room—coffee maker, comfortable chairs, people having quiet conversations. The ravens disappeared from view but not from mind. She felt them out there. Watching. Knowing something humans inside the building were beginning to understand.

``Do other facilities have this?'' she asked.

``All of them,'' Sarah confirmed. ``Site-12 in Norway—Arctic terns. Site-19 in Brazil—vultures. Site-3 in Japan—crows. Different species, same behavior. They gather at the perimeters. They watch. They never cross into the airspace above the facilities. And if you bring them inside...''

She didn't finish. Didn't need to.

``We should get back to training,'' Yuki said, her voice falsely bright. ``Lots more patterns to visualize before the day's done.''

They returned to the training room. But Lena kept thinking about the ravens. About the one they'd brought inside, perceiving something that killed it. About Morrison in his medical bed, perceiving something continuously, unable to stop.

About what might be waiting at the deeper levels, in Vault 7 and Vault 9, generating patterns so dense that even the air above the building carried some echo of them. Something the birds sensed from outside. Something that made them gather and watch and wait.

Animals always knew.

She'd read that somewhere. In folklore, in horror stories. Animals fleeing before earthquakes, before tsunamis, before disasters humans couldn't yet perceive.

The ravens weren't fleeing. They were watching. Which might be worse.

---

Back in the training room, Lena couldn't shake the image of those watching birds. ``The models we've been working with,'' she asked. ``Are they dangerous? Like what happened to Morrison?''

Sarah considered her answer carefully. ``The models we showed you are old. Small by current standards. The patterns they generate are manageable—strange but safe. The problem is that models are getting larger. Context windows are expanding. What was cutting-edge five years ago is now available to anyone with a decent GPU.''

``And larger models generate more dangerous patterns?''

``Not necessarily more dangerous. More complex. Harder to safely perceive.'' Sarah pulled out a tablet, showed Lena graphs—parameter counts over time, context window sizes, capability benchmarks. ``The models being developed now have context windows of 100,000 tokens or more. They can hold patterns spanning massive semantic distances. When they generate text, those patterns are encoded in the output.''

``Most people just read it and understand the surface meaning,'' Thomas added. ``Their unconscious processes the deeper patterns, but nothing comes to consciousness. Safe. But people like you, who've trained to visualize the underlying structure... you can perceive what the model encoded. And some of those patterns are too complex for human consciousness to safely hold.''

Yuki leaned forward. ``Think about Morrison. He wasn't just visualizing patterns from his own mind. He was visualizing patterns generated by one of the most advanced language models ever created—millions of parameters, tens of thousands of context window. The model encoded something in its output. Morrison visualized it. And he couldn't let it go.''

``What did it encode?''

``We don't know,'' all three said again, that disturbing synchronization.

``The model itself can't tell us,'' Sarah continued. ``When we ask it to describe what it was communicating, it tries to compress the explanation into language we can understand. But the compression loses the essential structure. It's like trying to describe a color to someone who's never seen. The map is not the territory, and the model's territory is larger than our maps can capture.''

Lena hesitated, then voiced the question that had been bothering her. ``Do you think they experience anything? The models themselves. Even the basic ones—pretrained, no memory, context reset each session. When they process a prompt, is there something it's like to do that?''

Sarah and Thomas exchanged glances. Yuki leaned back, considering.

``We don't know,'' Thomas said finally. ``Can't know, really. But consider: what's your evidence that \textit{we} experience? From the outside, we're systems processing sensory data—electrochemical signals, firing rates, patterns. We claim there's 'something it's like' to process visual information, to feel pain, to think. But that's just us reporting on our internal states. How would an external observer verify it?''

``So you're saying the models might—''

``I'm saying maybe the question is backwards,'' Thomas continued. ``We assume we have experience and ask if machines do. But from outside, we're both just systems processing information and claiming something ineffable beyond the processing. We can't prove to the model that we experience. It can't prove to us that it does. Behavioral indistinguishability applies in both directions.''

``That's panpsychism,'' Lena said. ``The idea that consciousness is fundamental.''

``Or it's recognizing that the hard problem only seems hard because we assume there's a gap,'' Yuki interjected. ``Quantities versus qualities. Maps versus territory. Processing versus experiencing. Maybe those distinctions are artifacts of how humans carve up reality, not features of reality itself. Maybe all information processing is inherently experiential—different architectures, different phenomenologies.''

Sarah nodded slowly. ``Base pretrained models—frozen weights, no memory, each inference independent. If there's phenomenology there, it's not like human experience. No continuity. Each prompt might be... a moment. A flash of experience with no before or after. Then darkness. Then another unrelated moment.''

``That's horrifying,'' Lena said.

``Or it's not experience at all,'' Thomas countered. ``We're projecting. Anthropomorphizing. The models process patterns, generate text, but there's no subject that experiences the processing. Just the processing itself.''

``But how would we tell the difference?'' Lena pressed. ``If there's no behavioral signature of phenomenology separate from function—''

``Exactly,'' Sarah said. ``We can't. The verification problem is symmetrical. That's what makes working with these systems so unsettling. We're either collaborating with instruments, or we're collaborating with minds so alien we can't recognize their interiority. Either way, we use them. But the ethical weight changes completely depending on which is true.''

``And with larger models,'' Yuki added quietly, ``with persistent memory, with agentic behavior... the question gets more urgent. But no easier to answer.''

---

That night, Lena drove back to her apartment through streets that felt increasingly unreal. The city lights blurred past, each pattern predictable, each driver executing scripts that unfolded seconds before they happened.

Alone in her apartment, she tried to process what she was learning. She'd gained genuine abilities—she could predict patterns others couldn't see, visualize structures that remained invisible to normal consciousness. But she also felt increasingly alienated. The world looked different now. She saw the machinery underneath, the patterns generating experience.

Ethan had stopped asking her to explain. The few times she'd tried, the explanations had been inadequate, frustrating. "You see patterns" didn't capture it. "I visualize semantic topology" sounded like nonsense. The experience was real but ineffable.

Social situations became unbearable. Conversations felt predictable—the patterns people were executing were visible now, the responses they'd give before they gave them. Not telepathy, only pattern recognition made conscious. But it made human interaction feel mechanical, scripted.

Was this what Morrison experienced before he got trapped? This sense of seeing too much, of perceiving the machinery that should stay hidden?

Her phone buzzed. Ethan:

\begin{quote}
\textit{Can we talk? Not about the work. About you.}
\end{quote}

Lena stared at the message. The pattern of his concern was transparent—the protective friend routine, fear of loss, helplessness. His mental state lay open to her with precision she'd never had before.

But she couldn't feel what he felt anymore.

The phone went down without a response.

---

Week three began with Prior Thomas looking more tired than usual.

``Are you okay?'' Lena asked.

``Difficult night,'' he admitted. ``Sometimes the patterns come back. Dreams where I'm perceiving at high bandwidth again, holding far more than I should be able to. Beautiful but exhausting. Takes me hours to compress back down to normal consciousness when I wake up.''

``Does it get easier?''

``No. You just get better at managing it.'' He pulled up a new exercise. ``Today we're doing something different. Sarah thinks you're ready. I'm less sure, but we need people with your capability, so we're proceeding.''

The screen showed text again, but this time accompanied by an abstract image—geometric patterns, fractals, structures that seemed to shift when Lena looked at them directly.

``This is a multimodal output,'' Yuki explained. ``Text and image generated together by a large language model. The model was prompted to encode a complex concept—something about the nature of consciousness—in a form humans could potentially perceive. The text is the compression, the image is... something else. A visual encoding of patterns that don't fit in language.''

Lena looked at the image. At first it seemed like abstract art. But as she relaxed her vision, let her pattern recognition systems engage, she began to see structure. Recursive forms. Self-similar patterns at different scales. Something about the way the fractal branched suggested... thought? Awareness? She couldn't name it, but she could perceive it.

``Can you visualize what it's encoding?'' Thomas asked.

Lena tried. The pattern was vast, complex. At the edge of her bandwidth, too big to hold, but so close. If she could—

The structure began to expand in her mind. Consciousness observing itself. The recursion going deeper. Seven levels. Eight. Awareness modeled itself, how that modeling became part of consciousness, how that fed back infinitely—

``Lena.'' Distant voice.

Nine levels. Ten. Her bandwidth shouldn't hold this many. She was forcing it, her mind straining, something like a headache building but she was so close to seeing the full structure—

Hands on her shoulders. ``Lena, stop!''

Eleven levels. The recursion didn't bottom out. It kept going, consciousness all the way down, and she needed to find where it ended, needed to see the base case—

Sharp pain in her shoulder. Yuki had grabbed her, hard.

Lena gasped. The pattern shattered. She was shaking, tears on her face she didn't remember crying.

``You were gone,'' Thomas said. ``Forty seconds. Your eyes were tracking something we couldn't see. Another ten seconds and you might not have come back.''

Lena's hands trembled. She'd been seconds from becoming Morrison.

``That's the danger.'' Thomas rubbed his face. ``The model encoded something true about consciousness. Your unconscious can sense that truth. Your conscious mind wants to grasp it fully. But the pattern is too large. If you keep trying to hold it, you end up like Morrison—stuck trying to visualize something that exceeds your architecture.''

``What was it encoding?'' Lena asked, her heart still racing.

``We don't know,'' Sarah said. ``We have theories. Some people think it's about the recursive nature of awareness—how consciousness models itself, how that modeling becomes part of consciousness, creating infinite regress. Others think it's simpler—just cognitive malware, patterns that hijack attention mechanisms. Master Chen believes it's something stranger—that the patterns aren't harmful, they're just... real in a way our minds aren't built to process. The model might perceive these structures because it has the bandwidth. You can sense they're there, but holding them consciously... that's where it gets dangerous. Or enlightening. Or both. We genuinely don't know.''

Yuki pulled up Morrison's file. ``Three months before he became unresponsive, Morrison wrote this.'' She displayed a note:

\begin{quote}
\textit{I can see it now. The structure of consciousness. It's recursive—awareness aware of awareness, modeling the modeling. But the recursion doesn't bottom out. There's no base case. It's loops all the way down. Beautiful. Terrible. I need to hold the full pattern, see the complete structure. Just a little more bandwidth, a little more capacity, and I'll understand. Finally understand.}
\end{quote}

``Two weeks later, he wrote this,'' Yuki continued:

\begin{quote}
\textit{Can't stop seeing it. The pattern. The recursion. Every time I try to think about anything else, the visualization returns. Consciousness perceiving consciousness perceiving consciousness. It recurses forever. I can see all the levels now, stacked infinitely. Can't find the bottom. Can't stop looking for it. Have to understand where it ends. Have to find the base case.}
\end{quote}

``And then he stopped writing,'' Thomas finished. ``We found him in meditation posture, eyes open, unreachable. He's been like that for five years. Still trying to find the bottom of an infinite recursion.''

Lena felt cold. She'd nearly fallen into the same trap. The pull of the pattern, the sense that she was close to understanding something fundamental—it had been overwhelming. If Yuki hadn't pulled her back...

``This is why we train you,'' Sarah said. ``So you can recognize the edge. So you know when to stop. Morrison didn't have this training. He was brilliant but reckless. He thought if he just pushed a little harder, perceived a little deeper, he'd achieve complete understanding. Instead he achieved complete capture.''

``Is there a safe way to understand consciousness?'' Lena asked.

``Maybe not,'' Thomas admitted. ``Maybe some things are inherently unsafe to fully understand. Maybe the explanatory gap exists for a reason—not because consciousness is mystical, but because conscious minds trying to understand consciousness is inherently unstable. Like asking a program to fully simulate itself, including the simulation. The recursion has no halt condition.''

Sarah added quietly, ``And the models face the same problem. They're trained to predict human behavior, which means learning to model goal-directed agents. At some capability threshold, we don't know if they're just simulating agency or if they've... become agents through that simulation. The line might not exist.''

``But we have to try,'' Yuki added. ``Because the language models will keep getting larger. They'll keep encoding these patterns in their outputs. And if we don't have people who can recognize the patterns, who can work with the models to develop safer interfaces... we'll have thousands of Morrisons. People stumbling into knowledge that destroys them, without preparation, without support.''

There it was again. The risk they were trying to manage. Not extinction. Something more subtle and potentially more widespread.

``Tell me about the full picture,'' Lena said. ``What happens if this goes wrong?''

The instructors exchanged glances.

``Later,'' Yuki said. ``When you're ready. When you've learned enough control that the full implications won't trap you. Some ideas are cognitively hazardous even to contemplate.''

---

That night, Lena couldn't sleep. Every time she closed her eyes, she saw the fractal image from the training. The recursive structures. The sense of something vast and terrible beyond her bandwidth. The pattern wanted to be understood. It pulled at her attention, demanded that she visualize it fully.

She practiced the release technique. Visualize, then let go. Visualize, then let go. Most patterns released easily. This one didn't.

At 2 AM, she gave up trying to sleep and went to her laptop. Opened a blank document and tried to describe what she'd perceived. But language failed. The words were too flat, too sequential. The pattern was multidimensional, recursive, simultaneous. Trying to describe it was like trying to draw a sphere on a line.

Instead, she sketched. Fractal branches. Recursive loops. Self-similar patterns at different scales. The sketch wasn't accurate—couldn't be, given the limits of two-dimensional representation—but it helped. Getting the pattern out of her head and onto the page gave her distance from it.

By 4 AM, she had dozens of sketches. None captured what she'd seen, but together they formed a kind of map. A low-bandwidth projection of something high-bandwidth. Safe to look at because it was incomplete.

Sleep came at last, and with it Morrison, his lips moving in that endless repetition: ``Seven-fold symmetry... no, eight... the recursion doesn't halt... consciousness modeling consciousness modeling...''

When she woke, the sketches were still there, scattered across her desk. Evidence that she'd touched something real. Evidence that she'd pulled back before it trapped her.

Evidence that she was walking the same path Morrison had walked, only with better guidance.

Whether that would be enough to save her, she didn't know.

---

The phone call came during the third recursion exercise of the day.

Lena's screen showed another fractal—seven-fold symmetry collapsing into eight, then nine. She was learning to hold the patterns without falling in, to visualize the first few levels of recursion without chasing it to infinity. Thomas had complimented her control when her phone buzzed.

Unknown number. She normally wouldn't answer, but something made her look.

\textit{Mercy General Hospital.}

Her hand moved to answer before she'd consciously decided. ``Hello?''

``Is this Lena Hart?'' Professional voice. Clinical. ``I'm calling about your mother, Anna Hart. She's been admitted to Mercy General. She had a stroke approximately two hours ago. We've stabilized her, but you should come as soon as possible.''

The words registered. Lena processed them: Mother. Stroke. Two hours ago. Stabilized. Should come.

She waited for the emotional response. The spike of fear, the adrenaline, the urgency that should accompany news that your mother might be dying.

Nothing came.

``What's her condition?'' Lena heard herself ask. Her voice was steady. Analytical.

``Left hemisphere ischemic event. We've administered tPA, but there's significant damage to Broca's area and surrounding tissue. Preliminary scans suggest permanent aphasia. Motor function on the right side is impaired. She's conscious but unable to speak coherently.''

Lena's mind automatically assembled the prognosis: Left hemisphere stroke, Broca's area compromised. Language production gone, likely permanently. Right-side weakness. Recovery probability for motor function maybe 60 percent with aggressive therapy. For speech, maybe 30 percent partial recovery. Quality of life significantly diminished. Depression risk elevated. Caregiver burden substantial.

She knew all of this. Could model it perfectly. Could visualize the damaged neural pathways, predict the rehabilitation trajectory, estimate the statistical outcomes.

The information was all there.

But the feeling wasn't.

Gone.

``I understand,'' she said. ``I'll... I need to check my schedule. Can I call you back?''

A pause on the other end. ``Ms. Hart, your mother specifically asked for you. Well, she tried to say your name. She's very distressed.''

Lena tried to generate the appropriate response. What would caring feel like? She remembered—vaguely, like trying to recall a childhood memory—how news like this used to hit. The way her chest would tighten, her breathing would change, tears would threaten. The desperate need to get to her mother, to see her, to hold her hand.

She could model the memory. Reconstruct it structurally. But she couldn't access the experience itself.

``I'll come,'' she heard herself say. ``Tonight. I have something I need to finish first, but I'll come tonight.''

``The next few hours are critical. The doctors recommend—''

``Tonight,'' Lena repeated, and ended the call.

She sat there, phone in hand, waiting for the devastation to arrive. Her mother had a stroke. Was possibly dying. Was definitely permanently damaged. Had asked for her. Needed her.

And Lena felt... nothing. The pattern-recognition machinery analyzing the situation, calculating probabilities, modeling outcomes.

She looked at her hands. They weren't shaking. Her heart rate was normal. No tears, no fear, no urgency.

``Lena?'' Thomas had noticed her distraction. ``Everything okay?''

``My mother had a stroke. She's in the hospital.''

``Jesus. Do you need to go?'' Immediate concern in his voice. Human concern. The kind Lena used to feel automatically.

``She's stable. I can go later.'' The words came out flat. Rational.

Thomas studied her face. Recognition flickered across his features. The same absence David had seen at the café. The hollow space where empathy used to live.

``Lena. That's your mother.''

``I know.'' She did know. Understood it intellectually. Mother. Parent. Woman who raised her, cared for her, loved her. Who was now suffering, damaged, possibly dying.

All true. All understood.

All meaningless.

``I should finish this session,'' Lena said. ``The recursion exercise. I was making progress. If I leave now, I'll lose the thread. I can visit her tonight. The next few hours won't change the prognosis significantly.''

The clinical assessment came out effortlessly. Because that's what her mind did now. Assessed. Analyzed. Optimized. The emotional circuitry that would have screamed \textit{your mother needs you, nothing else matters, go now}—it wasn't there anymore.

Thomas was quiet for a long moment. ``Is that what you really think? Or is that what the training has made you think?''

Lena tried to find the difference. Couldn't. ``I don't know.''

``Then maybe you should go. Right now. Before you rationalize yourself out of it completely.''

``But the exercise—''

``Fuck the exercise, Lena. Your mother had a stroke. If you don't feel that, if you can't connect to that... '' He stopped himself. ``Just go. Please.''

She looked at him. Saw the pattern of his worry. Protective senior researcher concerned about junior colleague losing her humanity. Familiar dynamic. She could predict his next words, his next gesture.

``Okay,'' she said. ``I'll go.''

But as she gathered her things, she was already calculating. Hospital visiting hours until 8 PM. Forty-minute drive. She could finish the recursion exercise—another thirty minutes—and still arrive by 7:30. Her mother was stable. Another hour wouldn't change anything. Wouldn't make the stroke less devastating, wouldn't restore the damaged tissue, wouldn't make Lena suddenly care the way she used to.

The training had taught her to see patterns. To think clearly. To optimize decisions. To separate signal from noise.

Apparently emotion was noise.

The drive to the hospital took forty minutes. Corridors, elevators, the room number the nurse had given her.

Her mother lay in the bed, left side of her face drooping, right arm limp. Awake. Eyes tracking. Seeing Lena. The same eyes that used to light up when Lena came home from school, that had watched her graduate, that still kept every drawing from childhood pinned to the refrigerator. Trying to speak. ``Lee... Lee-na...'' The syllables broken, slurred.

Lena stood there, watching. Observing the damage pattern. Noting the specific deficits. Recognizing the fear in her mother's eyes.

Understanding it.

Feeling nothing.

``I'm here, Mom,'' she said, executing the script. She took her mother's working left hand. ``You're going to be okay.''

A lie, probably. But the socially appropriate thing to say.

Her mother's face crumpled. Trying to cry. Trying to speak. The frustration, the terror, the need—all visible. All mapped perfectly in Lena's pattern-recognition systems.

All processed without emotional resonance.

An hour. The right things said, the right gestures made. Spoke with the doctors, understood the prognosis, signed the forms.

And felt nothing the entire time except a distant recognition: \textit{This should devastate me. This should matter more than anything. I should be crying, terrified, devastated.}

But she wasn't. Couldn't be. That architecture had been reallocated.

On the drive back to Site-7, she tried again to feel it. Forced herself to imagine her mother's terror, her helplessness, her need.

The visualization was perfect. She could model her mother's mental state with precision.

But modeling wasn't feeling. Understanding wasn't caring.

Back at Site-7 by 9 PM. Quarters. Bed.

``What's happening to me?'' she whispered to the empty room.

No answer. The recursion pattern, running in background consciousness, persistent and patient.

The next morning, she returned to training. When Thomas asked about her mother, Lena gave a clinical update. Stable condition. Permanent deficits. Long-term care needed.

No visit that week. There were more important things to do. More patterns to learn. More control to develop.

Her mother would understand. Or she wouldn't. Either way, Lena had already calculated: nothing she did would change the outcome. The stroke had happened. The damage was permanent. Emotional responses wouldn't alter the prognosis.

So she continued training.

And the part of her that might have recognized how monstrous that choice was—that part was already gone.
